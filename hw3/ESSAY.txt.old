Question 1:
 
Method 1 (Positional indexes)
Since the Vector Space Model works like a bag of words, we will use this concept and process the phrasal search to consider the ordering of words in a document. 

Algorithm sketch:
1. Treat the different terms in the phrasal search 
2. Continue as per normal with the usual vector space calculations and normalise for each term
3. OR the different terms together.

The result may not return documents where the words are in the correct order.
Eg: "Clinton beats Trump" and "Trump beats Clinton"

Thus we need to look look at the positional indices of the words to check the permutations.
We can also use a soft conjunction on the phrasal query to ensure that there are no missing words and use this to rank the documents.

Method 2 (biword indexes)
Instead of just looking at individual words, we could use biwords or triword indexes instead. 
This would ensure more accurate results by provide some form of ordering for us to search upon. 
However, this would take up alot of space.

Question 2:

Longer documents have naturally more terms and higher tf values. Also, they would have more distinct terms. 
This would lead to higher scores of longer documents due to a greater match to the query terms.

There are chances where there could be a lower score as longer documents can be verbose and cover multiple topics. 
However, even a small score is better than a 0 when calculating the weight. I believe that there is still a bias towards longer documents. EG:
	- Verbose: document is expressed in more words than needed. Low wt and low normalised score.
	- Multiple topics: Search terms would only match a small portion of the doc. This would result in a lower weight and subsequent score. Given let's say a research paper where the query is fully answered and elaborated very well in a part of the document. This would not be ranked highly because of the lower weightage of the query terms in the document due to the amount of extra words coming in from other parts of the reasearch paper.
	
The normalisation is insufficient. It is necessary to account for the length of the document. 
We should skew the score to account for the effect of document length on relevance similar to the textbook.

'ltc.lnc' is sufficient. In the Reuters collection, the document lengths are similar. 
The document structure is also standard. It is usually straight to the point and not verbose.

Question 3:

Yes. When the user specifies a zone to search for, we are able to make our searches relevant and return more accurate results to the user.
However this can be a problem if some documents do not use metadata. 
We may have relevant documents missing in our search results.
